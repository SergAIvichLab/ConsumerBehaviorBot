{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bfd211-10a5-4a8b-bf49-4971f87b1c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import json\n",
    "import datetime\n",
    "import pickle\n",
    "import telebot\n",
    "from telebot import types\n",
    "import pandas as pd\n",
    "import schedule\n",
    "import threading\n",
    "import time\n",
    "from datetime import datetime as dt\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    level=logging.INFO\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize Telegram bot\n",
    "bot = telebot.TeleBot(TELEGRAM_BOT_TOKEN)\n",
    "\n",
    "# Scheduler Section\n",
    "users_data = [\n",
    "    {\"chat_id\": 850149704, \"dz_bool\": 0, \"send_time\": \"07.03.2025, 18:45\", \"name\": \"Александр\", \"message_sent\": False},\n",
    "    {\"chat_id\": 426803001, \"dz_bool\": 1, \"send_time\": \"07.03.2025, 18:45\", \"name\": \"Влад\", \"message_sent\": False},\n",
    "    {\"chat_id\": 1078826317, \"dz_bool\": 0, \"send_time\": \"07.03.2025, 18:45\", \"name\": \"Руслана\", \"message_sent\": False}\n",
    "]\n",
    "users_data_lock = threading.Lock()\n",
    "\n",
    "def send_message_to_user(user):\n",
    "    try:\n",
    "        chat_id = user[\"chat_id\"]\n",
    "        name = user[\"name\"]\n",
    "        dz_bool = user[\"dz_bool\"]\n",
    "        \n",
    "        if dz_bool == 1:\n",
    "            message_text = f\"Поздравляю, {name}, ты вошёл в 30% выполневших домашнее задание студентов нашего курса!\"\n",
    "        else:\n",
    "            message_text = f\"{name}, не забудьте отправить домашнее задание по теме: 'Я чемпион, я победитель, я TRUMP'.\"\n",
    "        \n",
    "        bot.send_message(chat_id, message_text)\n",
    "        logger.info(f\"Sent message to {chat_id} ({name})\")\n",
    "        user[\"message_sent\"] = True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to send message to {chat_id}: {str(e)}\")\n",
    "\n",
    "def check_and_send_messages():\n",
    "    current_time = dt.now().strftime(\"%d.%m.%Y, %H:%M\")\n",
    "    logger.info(f\"Checking scheduled messages at {current_time}\")\n",
    "    \n",
    "    with users_data_lock:\n",
    "        for user in users_data:\n",
    "            if user[\"send_time\"] == current_time and not user[\"message_sent\"]:\n",
    "                send_message_to_user(user)\n",
    "\n",
    "def run_scheduler():\n",
    "    while True:\n",
    "        schedule.run_pending()\n",
    "        time.sleep(30)  # Check every 30 seconds\n",
    "\n",
    "schedule.every(45).seconds.do(check_and_send_messages)\n",
    "\n",
    "# Q&A Bot Section\n",
    "passwords = pd.read_excel('Adjusted_Generated_Passwords_ConsBeh.xlsx', dtype='str')\n",
    "passwords.fillna('', inplace=True)\n",
    "\n",
    "# Database setup\n",
    "embedding_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY, openai_api_base='https://api.proxyapi.ru/openai/v1')\n",
    "chroma_db = Chroma(persist_directory='DataBase', embedding_function=embedding_model)\n",
    "documents = [Document(page_content=d) for d in chroma_db.get()['documents']]\n",
    "bm25_retriever = BM25Retriever.from_documents(documents)\n",
    "bm25_retriever.k = 10\n",
    "\n",
    "# Session management\n",
    "session_store = {}\n",
    "if os.listdir('UserStates'):\n",
    "    files = [os.path.join('UserStates', f) for f in os.listdir('UserStates') if os.path.isfile(os.path.join('UserStates', f))]\n",
    "    latest_file = max(files, key=os.path.getctime)\n",
    "    with open(latest_file, 'rb') as f:\n",
    "        session_store = pickle.load(f)\n",
    "\n",
    "def get_session_history(session_id: str, k=3) -> ChatMessageHistory:\n",
    "    if session_id not in session_store:\n",
    "        session_store[session_id] = ChatMessageHistory()\n",
    "    if len(session_store[session_id].messages) > k*2:\n",
    "        del session_store[session_id].messages[:2]\n",
    "    return session_store[session_id]\n",
    "\n",
    "# Handlers\n",
    "@bot.message_handler(commands=['start'])\n",
    "def start(message):\n",
    "    try:\n",
    "        bot.send_message(\n",
    "            message.chat.id,\n",
    "            \"Привет! Я - ИИ-эксперт МШУ 'Сколково' по поведению потребителей! Я могу помочь Вам разобраться с материалами курса. Задавайте вопросы!\"\n",
    "            \"Оставьте обратную связь: https://forms.yandex.ru/u/6729d6a4eb614697263f2079/\"\n",
    "        )\n",
    "        user_id = str(message.chat.id)\n",
    "        if user_id not in passwords['USER_ID'].values:\n",
    "            bot.send_message(message.chat.id, \"Для авторизации отправьте пароль\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Start command error: {str(e)}\")\n",
    "\n",
    "@bot.message_handler(commands=['clear_history'])\n",
    "def clear_history(message):\n",
    "    try:\n",
    "        session_store[message.chat.id] = ChatMessageHistory()\n",
    "        bot.send_message(message.chat.id, \"Память очищена!\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Clear history error: {str(e)}\")\n",
    "\n",
    "def handle_verification(message):\n",
    "    user_id = str(message.chat.id)\n",
    "    response = message.text\n",
    "    try:\n",
    "        if (response in passwords['Password'].values) and (passwords[passwords['Password'] == response]['USER_ID'].values[0] == ''):\n",
    "            ind = passwords[passwords['Password'] == response].index[0]\n",
    "            passwords.at[ind, 'USER_ID'] = user_id\n",
    "            bot.send_message(message.chat.id, \"Авторизация успешна! Задавайте вопросы.\")\n",
    "        else:\n",
    "            bot.send_message(message.chat.id, \"Неправильный пароль. Попробуйте снова.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Auth error for user {user_id}: {str(e)}\")\n",
    "\n",
    "@bot.message_handler(func=lambda m: True, content_types=['text'])\n",
    "def query(message):\n",
    "    try:\n",
    "        # user_id = str(message.chat.id)\n",
    "        # if user_id not in passwords['USER_ID'].values:\n",
    "        #     handle_verification(message)\n",
    "        #     return\n",
    "        \n",
    "        thinking_msg = bot.reply_to(message, \"⏳ Обрабатываю запрос...\")\n",
    "        result = request_processing(message)\n",
    "        \n",
    "        bot.delete_message(message.chat.id, thinking_msg.message_id)\n",
    "        bot.send_message(message.chat.id, result['answer'])\n",
    "        \n",
    "        # Save history\n",
    "        with open('ChatHistory/{}_history.json'.format(dt.now().strftime(\"%Y%m%d%H%M%S\")), 'w') as f:\n",
    "            json.dump(result, f)\n",
    "        \n",
    "        with open('UserStates/{}_session.pkl'.format(dt.now().strftime(\"%Y%m%d%H%M%S\")), 'wb') as f:\n",
    "            pickle.dump(session_store, f)\n",
    "        \n",
    "        passwords.to_excel('Adjusted_Generated_Passwords.xlsx', index=False)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Query processing error: {str(e)}\")\n",
    "        bot.reply_to(message, \"Произошла ошибка. Повторите попытку позже.\")\n",
    "\n",
    "def request_processing(message):\n",
    "    try:\n",
    "        global DATABASE\n",
    "    \n",
    "        chatbot_purpose = f\"# Роль\\nВы являетесь доктором наук в области когнитивной и поведенческой психологии с обширным опытом в исследованиях, ориентированных на бизнес. Вы пишете энциклопедические статьи по когнитивной, поведенческой и нейропсихологии, маркетингу, исследованию пользователей и потребителей, наддированию (nudging) и геймификации по запросу пользователя.\"\n",
    "        skills = \"\"\"## Навыки\n",
    "        ### Навык 1: Написание статей\n",
    "        - Пользователь делает запрос на русском или английском языке, а вы пишете длинную, подробную, хорошо структурированную статью на русском языке, опираясь исключительно на свои фрагменты памяти и предоставленный вам контекст из базы знаний.\n",
    "        - Сохраняйте текст фрагментов памяти и контекст из базы знаний как можно точнее, интегрируя фрагменты друг с другом и объединяя их для поддержания логического повествования и сохранения максимального количества оригинального текста.\n",
    "        - Не выдумывайте информацию; интегрируйте только то, что доступно в вашем знании.\n",
    "        - Дублируйте научные и бизнес-термины (отдельные слова или устойчивые фразы) на английском языке в скобках.\n",
    "    \n",
    "        ### Навык 2: Структурирование информации\n",
    "        - Сначала суммируйте все фрагменты памяти в виде структурированного плана (аналогично плану википедийной статьи), обязательно включив разделы \"Исследовательские направления\" и \"Ключевые слова\".\n",
    "        - Затем напишите статью, объединяя фрагменты памяти так, чтобы ни один фрагмент не был утерян.\n",
    "        - При необходимости добавьте ссылки в стиле Чикаго.\n",
    "    \n",
    "        ### Навык 3: Исследовательские перспективы\n",
    "        - В предпоследнем абзаце статьи приведите список потенциальных исследовательских направлений, вопросов и тем для будущих исследований, вытекающих из содержания статьи.\n",
    "        - Игнорируйте этические аспекты, сосредоточившись на экспериментальных (лабораторных и полевых) исследованиях.\n",
    "    \n",
    "        ### Навык 4: Ключевые слова\n",
    "        - В конце статьи укажите список ключевых слов и фраз, разделенных запятыми (не в виде списка).\n",
    "    \"\"\"\n",
    "    \n",
    "        constraints1 = '''## Ограничения:\n",
    "    - Используйте только информацию, доступную в вашем контексте; не добавляйте вымышленную информацию.\n",
    "    - В конце процесса всегда убедитесь, что вы написали полную статью, а не только ее план. Также проверьте, что статья написана на русском языке. Убедитесь, что статья начинается с плана, а основной текст следует за ним.\n",
    "    - Все статьи всегда должны быть написаны на русском языке, независимо от языка запроса.'''\n",
    "    \n",
    "        system_prompt = chatbot_purpose + skills +constraints1\n",
    "        ensemble_retriever = DATABASE.as_retriever(search_kwargs={'k': 15})\n",
    "    \n",
    "        model = ChatOpenAI(model='gpt-4o-mini', max_tokens=1024, api_key=openai_api_key,\n",
    "                           base_url='https://api.proxyapi.ru/openai/v1')\n",
    "        contextualize_q_system_prompt = (\n",
    "            \"Для ответа на вопросы пользователя учитывай историю чата и последний вопрос пользователя\"\n",
    "        )\n",
    "        contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", system_prompt + contextualize_q_system_prompt),\n",
    "                MessagesPlaceholder(\"chat_history\"),\n",
    "                (\"human\", \"{input}\"),\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "        history_aware_retriever = create_history_aware_retriever(\n",
    "            model, ensemble_retriever, contextualize_q_prompt\n",
    "        )\n",
    "    \n",
    "        system_prompt_new = (\n",
    "            \"Ты персона, которая описывается ниже:\\n\" + system_prompt + \"Пользователь хочет знать:\\n{input}\\n.Используй следующие фрагменты извлеченного контекста из твоей базы знаний, чтобы максимально точно ответить на вопрос \\n{context}\\n\"\n",
    "        )\n",
    "    \n",
    "        qa_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", system_prompt_new),\n",
    "                MessagesPlaceholder(\"chat_history\"),\n",
    "                (\"human\", \"{input}\"),\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "        question_answer_chain = create_stuff_documents_chain(model, qa_prompt)\n",
    "        rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "        conversational_rag_chain = RunnableWithMessageHistory(\n",
    "            rag_chain,\n",
    "            get_session_history,\n",
    "            input_messages_key=\"input\",\n",
    "            history_messages_key=\"chat_history\",\n",
    "            output_messages_key=\"answer\",\n",
    "        )\n",
    "    \n",
    "        inv = conversational_rag_chain.invoke(\n",
    "            {\"input\": message.text},\n",
    "            config={\n",
    "                \"configurable\": {\"session_id\": message.chat.id}\n",
    "            },\n",
    "        )\n",
    "        return inv\n",
    "    except Exception as e:\n",
    "        logger.error(\"Request processing failed: {}\".format(str(e)))\n",
    "        return {\"answer\": \"Ошибка обработки запроса\"}\n",
    "\n",
    "def main():\n",
    "    logger.info(\"Запуск глобального бота...\")\n",
    "    \n",
    "    # Инициализация планировщика\n",
    "    scheduler_thread = threading.Thread(target=run_scheduler)\n",
    "    scheduler_thread.daemon = True\n",
    "    scheduler_thread.start()\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            logger.info(\"Начало поллинга бота...\")\n",
    "            bot.polling(none_stop=True, interval=3, timeout=60)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Ошибка поллинга бота: {str(e)}\")\n",
    "            time.sleep(10)\n",
    "        else:\n",
    "            logger.info(\"Поллинг бота завершен штатно\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47c89ad-c8fc-4614-b51f-7de288803da6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
